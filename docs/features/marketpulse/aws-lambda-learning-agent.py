"""
Market Pulse Learning Agent - Signal Prediction

Layer 2: Learning Layer (AWS Lambda)
èŒè´£: å­¦ä¹ å†å²æ•°æ®ï¼Œé¢„æµ‹ Compute Agent çš„ Signal
æŠ€æœ¯: AWS Lambda (Python 3.11), EventBridge, boto3, scikit-learn

æ¨¡å‹: çº¿æ€§å›å½’ / Ridgeï¼ˆå…ˆç”¨ç®€å•æ¨¡å‹ï¼‰
ç‰¹å¾: 8 ä¸ªç‰¹å¾ï¼ˆret_1, ret_2, range, vol_norm, rolling statsï¼‰
è®­ç»ƒé¢‘ç‡: æ¯ 1 å°æ—¶
ç›®æ ‡: é¢„æµ‹ Compute Agent çš„ Signal

è¯„ä¼°æŒ‡æ ‡:
- RÂ² Scoreï¼ˆå†³å®šç³»æ•°ï¼‰
- MAEï¼ˆå¹³å‡ç»å¯¹è¯¯å·®ï¼‰
- æ”¶æ•›æ ‡å‡†: MAE < 0.1 æŒç»­ 50 ä¸ª bars æˆ– RÂ² > 0.9 æŒç»­ 1 å¤©

è§¦å‘æ–¹å¼:
- EventBridge: æ¯ 1 å°æ—¶è‡ªåŠ¨è§¦å‘
- æ‰‹åŠ¨è§¦å‘: é€šè¿‡ AWS Console æˆ– CLI
"""

import json
import boto3
import os
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Any, Optional
from statistics import mean, stdev
import logging

# é…ç½®æ—¥å¿—
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# å°è¯•å¯¼å…¥ scikit-learn
try:
    from sklearn.linear_model import Ridge
    from sklearn.metrics import r2_score, mean_absolute_error
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    logger.warning("scikit-learn not available, using simple linear regression")

# åˆå§‹åŒ– AWS å®¢æˆ·ç«¯
s3_client = boto3.client('s3')
BUCKET_NAME = os.environ.get('S3_BUCKET_NAME')

# æ”¯æŒçš„è‚¡ç¥¨åˆ—è¡¨
SUPPORTED_TICKERS = ['AAPL', 'MSFT', 'AMZN', 'NVDA', 'TSLA', 'META', 'GOOGL', 'JPM', 'XOM', 'SPY']

# æœ€å°‘éœ€è¦å¤šå°‘æ¡ compute ä¿¡å·æ‰è®­ç»ƒï¼ˆé™ä½ååŒä¸€å¤©å†…å¤šæ¬¡ Compute å³å¯å¼€å§‹å­¦ä¹ ï¼‰
MIN_SIGNALS_TO_TRAIN = 14
MIN_TRAINING_SAMPLES = 3


# ============================================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•°æ®è¯»å–
# ============================================================================

def read_compute_signals(date: str, hours: int = 24) -> Dict[str, List[Dict[str, Any]]]:
    """
    è¯»å–è¿‡å» N å°æ—¶çš„ Compute Agent signals
    
    Args:
        date: æ—¥æœŸå­—ç¬¦ä¸² "YYYY-MM-DD"
        hours: è¯»å–å¤šå°‘å°æ—¶çš„æ•°æ®ï¼ˆé»˜è®¤ 24 å°æ—¶ï¼‰
    
    Returns:
        Dict[ticker, List[signal_data]]: æŒ‰ ticker åˆ†ç»„çš„ä¿¡å·æ•°æ®
    """
    signals_by_ticker = {ticker: [] for ticker in SUPPORTED_TICKERS}
    
    # è¯»å–ä»Šå¤©å’Œæ˜¨å¤©çš„æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
    end_date = datetime.fromisoformat(date).date()
    
    for i in range(hours // 24 + 1):  # è‡³å°‘è¯»å–ä»Šå¤©å’Œæ˜¨å¤©
        check_date = (end_date - timedelta(days=i)).isoformat()
        key = f"processed-data/{check_date}/compute-signals.json"
        
        try:
            response = s3_client.get_object(Bucket=BUCKET_NAME, Key=key)
            content = response['Body'].read().decode('utf-8')
            data = json.loads(content)
            
            signals = data.get('signals', [])
            
            # æŒ‰ ticker åˆ†ç»„
            for signal in signals:
                ticker = signal.get('ticker')
                if ticker in signals_by_ticker:
                    # æ£€æŸ¥æ—¶é—´æˆ³æ˜¯å¦åœ¨èŒƒå›´å†…
                    signal_time = signal.get('timestamp')
                    if signal_time:
                        try:
                            signal_dt = datetime.fromisoformat(signal_time.replace('Z', '+00:00'))
                            cutoff_time = datetime.now(timezone.utc) - timedelta(hours=hours)
                            if signal_dt >= cutoff_time:
                                signals_by_ticker[ticker].append(signal)
                        except:
                            # å¦‚æœæ—¶é—´è§£æå¤±è´¥ï¼Œä»ç„¶æ·»åŠ ï¼ˆå¯èƒ½æ˜¯ä»Šå¤©çš„æ•°æ®ï¼‰
                            signals_by_ticker[ticker].append(signal)
            
        except s3_client.exceptions.NoSuchKey:
            logger.debug(f"No compute signals found for {check_date}")
            continue
        except Exception as e:
            logger.warning(f"Error reading signals for {check_date}: {e}")
            continue
    
    # æŒ‰æ—¶é—´æˆ³æ’åº
    for ticker in signals_by_ticker:
        signals_by_ticker[ticker].sort(key=lambda x: x.get('timestamp', ''))
    
    logger.info(f"âœ… Read signals for {sum(len(v) for v in signals_by_ticker.values())} total entries")
    return signals_by_ticker


# ============================================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šç‰¹å¾æå–
# ============================================================================

def extract_features(signals: List[Dict[str, Any]], index: int) -> Optional[List[float]]:
    """
    æå– 8 ä¸ªç‰¹å¾ç”¨äºæ¨¡å‹è®­ç»ƒ
    
    ç‰¹å¾åˆ—è¡¨:
    1. ret_1: å‰ 1 ä¸ª bar çš„ Return
    2. ret_2: å‰ 2 ä¸ª bar çš„ Return
    3. range: å½“å‰ bar çš„ (High - Low) / Openï¼ˆéœ€è¦ä»åŸå§‹æ•°æ®è·å–ï¼Œè¿™é‡Œç”¨ Return çš„ç»å¯¹å€¼è¿‘ä¼¼ï¼‰
    4. vol_norm: å½“å‰ Vol ç›¸å¯¹äºå†å²å¹³å‡çš„æ ‡å‡†åŒ–å€¼
    5. rolling_mean_5: è¿‡å» 5 ä¸ª bars çš„ Return å‡å€¼
    6. rolling_mean_10: è¿‡å» 10 ä¸ª bars çš„ Return å‡å€¼
    7. rolling_std_5: è¿‡å» 5 ä¸ª bars çš„ Return æ ‡å‡†å·®
    8. rolling_std_10: è¿‡å» 10 ä¸ª bars çš„ Return æ ‡å‡†å·®
    
    Args:
        signals: ä¿¡å·æ•°æ®åˆ—è¡¨ï¼ˆå·²æ’åºï¼‰
        index: å½“å‰ç´¢å¼•ï¼ˆè¦é¢„æµ‹çš„ä¿¡å·ç´¢å¼•ï¼‰
    
    Returns:
        List[float]: 8 ä¸ªç‰¹å¾å€¼ï¼Œæˆ– Noneï¼ˆå¦‚æœæ•°æ®ä¸è¶³ï¼‰
    """
    if index < 10:  # éœ€è¦è‡³å°‘ 10 ä¸ªå†å²æ•°æ®ç‚¹
        return None
    
    # æå– Returns å’Œ Vols
    returns = [s.get('return', 0) for s in signals[:index+1]]
    vols = [s.get('vol', 1e-6) for s in signals[:index+1]]
    
    if len(returns) < 10:
        return None
    
    # 1. ret_1: å‰ 1 ä¸ª bar çš„ Return
    ret_1 = returns[index - 1] if index > 0 else 0.0
    
    # 2. ret_2: å‰ 2 ä¸ª bar çš„ Return
    ret_2 = returns[index - 2] if index > 1 else 0.0
    
    # 3. range: ç”¨ Return çš„ç»å¯¹å€¼è¿‘ä¼¼ï¼ˆå®é™…åº”è¯¥ä»åŸå§‹ bar æ•°æ®è·å–ï¼‰
    current_return = returns[index]
    range_feature = abs(current_return)
    
    # 4. vol_norm: å½“å‰ Vol ç›¸å¯¹äºå†å²å¹³å‡çš„æ ‡å‡†åŒ–å€¼
    current_vol = vols[index]
    avg_vol = mean(vols[:index]) if index > 0 else current_vol
    vol_norm = (current_vol - avg_vol) / (avg_vol + 1e-6) if avg_vol > 0 else 0.0
    
    # 5. rolling_mean_5: è¿‡å» 5 ä¸ª bars çš„ Return å‡å€¼
    rolling_mean_5 = mean(returns[max(0, index-5):index]) if index >= 5 else mean(returns[:index]) if index > 0 else 0.0
    
    # 6. rolling_mean_10: è¿‡å» 10 ä¸ª bars çš„ Return å‡å€¼
    rolling_mean_10 = mean(returns[max(0, index-10):index]) if index >= 10 else mean(returns[:index]) if index > 0 else 0.0
    
    # 7. rolling_std_5: è¿‡å» 5 ä¸ª bars çš„ Return æ ‡å‡†å·®
    rolling_std_5 = stdev(returns[max(0, index-5):index]) if index >= 5 and len(returns[max(0, index-5):index]) > 1 else 0.0
    
    # 8. rolling_std_10: è¿‡å» 10 ä¸ª bars çš„ Return æ ‡å‡†å·®
    rolling_std_10 = stdev(returns[max(0, index-10):index]) if index >= 10 and len(returns[max(0, index-10):index]) > 1 else 0.0
    
    return [
        ret_1,
        ret_2,
        range_feature,
        vol_norm,
        rolling_mean_5,
        rolling_mean_10,
        rolling_std_5,
        rolling_std_10
    ]


# ============================================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹
# ============================================================================

def train_and_predict(signals: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    è®­ç»ƒæ¨¡å‹å¹¶é¢„æµ‹å½“å‰ Signal
    
    Args:
        signals: ä¿¡å·æ•°æ®åˆ—è¡¨ï¼ˆè‡³å°‘éœ€è¦ 20 ä¸ªï¼‰
    
    Returns:
        Dict: {
            "signal_predicted": 0.48,
            "signal_actual": 0.52,
            "r2_score": 0.85,
            "mae": 0.08,
            "training_iterations": 24,
            "converged": False,
            "features": {...}
        }
    """
    if len(signals) < MIN_SIGNALS_TO_TRAIN:
        logger.warning(f"Insufficient signals for training: {len(signals)} < {MIN_SIGNALS_TO_TRAIN}")
        return {
            "signal_predicted": 0.0,
            "signal_actual": signals[-1].get('signal', 0.0) if signals else 0.0,
            "r2_score": 0.0,
            "mae": 1.0,
            "training_iterations": 0,
            "converged": False,
            "error": "Insufficient data"
        }
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    X_train = []  # ç‰¹å¾
    y_train = []  # ç›®æ ‡ï¼ˆSignalï¼‰
    
    # ä½¿ç”¨å‰ N-1 ä¸ªä¿¡å·ä½œä¸ºè®­ç»ƒæ•°æ®ï¼Œæœ€åä¸€ä¸ªä½œä¸ºæµ‹è¯•
    for i in range(10, len(signals) - 1):
        features = extract_features(signals, i)
        if features:
            X_train.append(features)
            y_train.append(signals[i].get('signal', 0.0))
    
    if len(X_train) < MIN_TRAINING_SAMPLES:
        logger.warning(f"Insufficient training samples: {len(X_train)} < {MIN_TRAINING_SAMPLES}")
        return {
            "signal_predicted": 0.0,
            "signal_actual": signals[-1].get('signal', 0.0),
            "r2_score": 0.0,
            "mae": 1.0,
            "training_iterations": 0,
            "converged": False,
            "error": "Insufficient training samples"
        }
    
    # è·å–å½“å‰ä¿¡å·ï¼ˆæœ€åä¸€ä¸ªï¼‰
    current_signal = signals[-1]
    current_features = extract_features(signals, len(signals) - 1)
    signal_actual = current_signal.get('signal', 0.0)
    
    if not current_features:
        return {
            "signal_predicted": 0.0,
            "signal_actual": signal_actual,
            "r2_score": 0.0,
            "mae": 1.0,
            "training_iterations": 0,
            "converged": False,
            "error": "Cannot extract features for current signal"
        }
    
    # è®­ç»ƒæ¨¡å‹
    if SKLEARN_AVAILABLE:
        # ä½¿ç”¨ Ridge å›å½’
        model = Ridge(alpha=1.0)
        scaler = StandardScaler()
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        X_train_scaled = scaler.fit_transform(X_train)
        X_current_scaled = scaler.transform([current_features])
        
        # è®­ç»ƒ
        model.fit(X_train_scaled, y_train)
        
        # é¢„æµ‹
        signal_predicted = model.predict(X_current_scaled)[0]
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆåœ¨è®­ç»ƒé›†ä¸Šï¼‰
        y_pred_train = model.predict(X_train_scaled)
        r2 = r2_score(y_train, y_pred_train)
        mae = mean_absolute_error(y_train, y_pred_train)
        
    else:
        # ç®€å•çº¿æ€§å›å½’ï¼ˆä¸ä½¿ç”¨ scikit-learnï¼‰
        # ä½¿ç”¨æœ€å°äºŒä¹˜æ³•
        import numpy as np
        
        X_train_array = np.array(X_train)
        y_train_array = np.array(y_train)
        
        # æ·»åŠ åç½®é¡¹
        X_train_bias = np.column_stack([np.ones(len(X_train)), X_train_array])
        
        # æœ€å°äºŒä¹˜è§£
        try:
            coeffs = np.linalg.lstsq(X_train_bias, y_train_array, rcond=None)[0]
            
            # é¢„æµ‹
            X_current_bias = np.array([1.0] + current_features)
            signal_predicted = np.dot(X_current_bias, coeffs)
            
            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
            y_pred_train = np.dot(X_train_bias, coeffs)
            r2 = 1 - np.sum((y_train_array - y_pred_train) ** 2) / np.sum((y_train_array - np.mean(y_train_array)) ** 2)
            mae = np.mean(np.abs(y_train_array - y_pred_train))
            
        except Exception as e:
            logger.error(f"Error in simple linear regression: {e}")
            signal_predicted = signal_actual
            r2 = 0.0
            mae = 1.0
    
    # æ£€æŸ¥æ”¶æ•›çŠ¶æ€ï¼ˆç®€åŒ–ç‰ˆï¼šåŸºäºå½“å‰æŒ‡æ ‡ï¼‰
    converged = (mae < 0.1) and (r2 > 0.9)
    
    return {
        "signal_predicted": round(signal_predicted, 4),
        "signal_actual": round(signal_actual, 4),
        "r2_score": round(r2, 4),
        "mae": round(mae, 4),
        "training_iterations": len(X_train),
        "converged": converged,
        "features": {
            "ret_1": round(current_features[0], 6),
            "ret_2": round(current_features[1], 6),
            "range": round(current_features[2], 6),
            "vol_norm": round(current_features[3], 6),
            "rolling_mean_5": round(current_features[4], 6),
            "rolling_mean_10": round(current_features[5], 6),
            "rolling_std_5": round(current_features[6], 6),
            "rolling_std_10": round(current_features[7], 6)
        }
    }


# ============================================================================
# ç¬¬å››éƒ¨åˆ†ï¼šä¸»å¤„ç†æµç¨‹
# ============================================================================

def process_learning_task(date: str) -> Dict[str, Any]:
    """
    å¤„ç†å­¦ä¹ ä»»åŠ¡
    
    Args:
        date: æ—¥æœŸå­—ç¬¦ä¸² "YYYY-MM-DD"
    
    Returns:
        Dict: å¤„ç†ç»“æœç»Ÿè®¡
    """
    logger.info(f"ğŸ§  Starting learning task for {date}")
    
    # è¯»å– Compute Agent signalsï¼ˆè¿‡å» 7 å¤© â‰ˆ 168 å°æ—¶ï¼‰
    # å¢åŠ æ—¶é—´çª—å£ï¼Œè®©å­¦ä¹ åºåˆ—æ›´é•¿ï¼Œæ¨¡å‹å¯ä»¥ä½¿ç”¨æ›´å¤šå†å²æ ·æœ¬
    signals_by_ticker = read_compute_signals(date, hours=168)
    
    all_models = {}
    
    # å¯¹æ¯ä¸ª ticker è®­ç»ƒæ¨¡å‹ï¼ˆè‡³å°‘ MIN_SIGNALS_TO_TRAIN æ¡æ‰è®­ç»ƒï¼Œä¾¿äºåŒä¸€å¤©å†…å‡ºå­¦ä¹ ç»“æœï¼‰
    for ticker in SUPPORTED_TICKERS:
        signals = signals_by_ticker.get(ticker, [])
        
        if len(signals) < MIN_SIGNALS_TO_TRAIN:
            logger.warning(f"âš ï¸  Insufficient signals for {ticker}: {len(signals)} < {MIN_SIGNALS_TO_TRAIN}")
            continue
        
        try:
            # è®­ç»ƒæ¨¡å‹å¹¶é¢„æµ‹
            model_result = train_and_predict(signals)
            all_models[ticker] = model_result
            
            logger.info(f"âœ… Trained model for {ticker}: RÂ²={model_result['r2_score']:.4f}, MAE={model_result['mae']:.4f}")
            
        except Exception as e:
            logger.error(f"âŒ Error training model for {ticker}: {e}")
            continue
    
    logger.info(f"âœ… Trained {len(all_models)} models")
    
    # å­˜å‚¨ç»“æœåˆ° S3
    processed_prefix = f"processed-data/{date}/"
    
    learning_data = {
        "date": date,
        "processed_at": datetime.now(timezone.utc).isoformat().replace('+00:00', 'Z'),
        "models": all_models,
        "tickers_processed": len(all_models),
        "total_tickers": len(SUPPORTED_TICKERS)
    }
    
    try:
        s3_client.put_object(
            Bucket=BUCKET_NAME,
            Key=f"{processed_prefix}learning-signals.json",
            Body=json.dumps(learning_data, default=str, ensure_ascii=False, indent=2),
            ContentType='application/json'
        )
        logger.info(f"âœ… Stored learning signals to S3")
    except Exception as e:
        logger.error(f"âŒ Error storing learning signals: {e}")
        raise
    
    return {
        "success": True,
        "date": date,
        "models_count": len(all_models),
        "tickers_processed": len(all_models),
        "total_tickers": len(SUPPORTED_TICKERS)
    }


# ============================================================================
# Lambda Handler (å…¥å£ç‚¹)
# ============================================================================

def lambda_handler(event, context):
    """
    Lambda å‡½æ•°å…¥å£ç‚¹
    
    è§¦å‘æ–¹å¼ï¼š
    1. EventBridge (å®šæ—¶): æ¯ 1 å°æ—¶
    2. æ‰‹åŠ¨è§¦å‘: å¯ä»¥ä¼ é€’ date å‚æ•°
    
    Args:
        event: Lambda äº‹ä»¶å¯¹è±¡
        context: Lambda ä¸Šä¸‹æ–‡
    
    Returns:
        Dict: å¤„ç†ç»“æœ
    """
    try:
        # è·å–æ—¥æœŸï¼ˆä» event æˆ–ä½¿ç”¨ä»Šå¤©ï¼‰
        date = event.get('date') or datetime.now(timezone.utc).date().isoformat()
        
        logger.info(f"ğŸ§  Learning Agent started for {date}")
        logger.info(f"ğŸ“¦ Bucket: {BUCKET_NAME}")
        
        if not BUCKET_NAME:
            raise ValueError("S3_BUCKET_NAME environment variable not set")
        
        # æ‰§è¡Œå­¦ä¹ ä»»åŠ¡
        result = process_learning_task(date)
        
        logger.info(f"âœ… Learning completed: {result}")
        
        return {
            'statusCode': 200,
            'body': json.dumps(result, default=str)
        }
        
    except Exception as e:
        logger.error(f"âŒ Error in learning agent: {e}", exc_info=True)
        
        return {
            'statusCode': 500,
            'body': json.dumps({
                'success': False,
                'error': str(e)
            })
        }
