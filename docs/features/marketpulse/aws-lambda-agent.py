"""
Market Pulse AWS Lambda Agent (v3 - Minimal)

Layer 2: Processing Layer
èŒè´£: è¯»å–åŸå§‹æ•°æ®ï¼Œè®¡ç®— pulse æŒ‡æ ‡
æŠ€æœ¯: AWS Lambda (Python 3.11), EventBridge, boto3, statistics

å¤„ç†æµç¨‹ (v3 - simplified):
1. è¯»å– raw-data/ (ä» Storage Layer)
2. è®¡ç®—æŒ‡æ ‡ (velocity, volume surge, volatility, stress, breadth)
3. å­˜å‚¨ç»“æœ (åˆ° Storage Layer)

Deleted (v3):
- âŒ å­¦ä¹ æ¨¡å¼ (learn_patterns)
- âŒ ç”Ÿæˆæ€»ç»“ (generate_daily_summary)
- âŒ Insights å­˜å‚¨

è§¦å‘æ–¹å¼:
- EventBridge: æ¯ 5 åˆ†é’Ÿè‡ªåŠ¨è§¦å‘ (è¿‘å®æ—¶)
- æ‰‹åŠ¨è§¦å‘: é€šè¿‡ AWS Console æˆ– CLI
"""

import json
import boto3
import os
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Any, Optional
from statistics import mean, stdev
import logging

# é…ç½®æ—¥å¿—
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# åˆå§‹åŒ– AWS å®¢æˆ·ç«¯
s3_client = boto3.client('s3')
BUCKET_NAME = os.environ.get('S3_BUCKET_NAME')

# ============================================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•°æ®è¯»å–
# ============================================================================

def read_raw_data_from_s3(date: str) -> Dict[str, List[Dict[str, Any]]]:
    """
    ä» S3 è¯»å–æŒ‡å®šæ—¥æœŸçš„åŸå§‹æ•°æ®
    
    Args:
        date: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ ¼å¼ "YYYY-MM-DD"
    
    Returns:
        Dict[ticker, List[bar_data]]: æŒ‰ ticker åˆ†ç»„çš„åŸå§‹ bar æ•°æ®
    
    ç¤ºä¾‹è¿”å›:
        {
            "SPY": [
                {"timestamp": "2024-01-15T10:00:00Z", "bar_data": {...}},
                {"timestamp": "2024-01-15T10:01:00Z", "bar_data": {...}},
            ],
            "QQQ": [...]
        }
    """
    raw_bars_by_ticker = {}
    prefix = f"raw-data/{date}/"
    
    logger.info(f"ğŸ“¥ Reading raw data from S3: {prefix}")
    
    try:
        # åˆ—å‡ºæ‰€æœ‰å¯¹è±¡
        paginator = s3_client.get_paginator('list_objects_v2')
        pages = paginator.paginate(Bucket=BUCKET_NAME, Prefix=prefix)
        
        total_files = 0
        for page in pages:
            if 'Contents' not in page:
                continue
            
            for obj in page['Contents']:
                key = obj['Key']
                # è§£æè·¯å¾„: raw-data/YYYY-MM-DD/ticker/timestamp.json
                parts = key.split('/')
                
                if len(parts) >= 4:
                    ticker = parts[2]  # ticker æ˜¯è·¯å¾„çš„ç¬¬ä¸‰éƒ¨åˆ†
                    
                    # è¯»å– JSON æ–‡ä»¶
                    try:
                        response = s3_client.get_object(Bucket=BUCKET_NAME, Key=key)
                        bar_data = json.loads(response['Body'].read().decode('utf-8'))
                        
                        if ticker not in raw_bars_by_ticker:
                            raw_bars_by_ticker[ticker] = []
                        raw_bars_by_ticker[ticker].append(bar_data)
                        total_files += 1
                    except Exception as e:
                        logger.warning(f"Failed to read {key}: {e}")
                        continue
        
        logger.info(f"âœ… Read {total_files} raw bar files for {len(raw_bars_by_ticker)} tickers")
        
        # æŒ‰æ—¶é—´æˆ³æ’åº
        for ticker in raw_bars_by_ticker:
            raw_bars_by_ticker[ticker].sort(
                key=lambda x: x.get('timestamp', '')
            )
        
        return raw_bars_by_ticker
        
    except Exception as e:
        logger.error(f"âŒ Error reading raw data: {e}")
        return {}


# ============================================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šPulse æŒ‡æ ‡è®¡ç®—
# ============================================================================

def calculate_price_velocity(prices: List[float]) -> float:
    """
    è®¡ç®—ä»·æ ¼é€Ÿåº¦ï¼ˆä»·æ ¼å˜åŒ–ç‡ï¼‰
    
    å…¬å¼: (æœ€æ–°ä»·æ ¼ - 5åˆ†é’Ÿå‰ä»·æ ¼) / 5åˆ†é’Ÿå‰ä»·æ ¼ * 100
    
    Args:
        prices: ä»·æ ¼åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰
    
    Returns:
        float: ä»·æ ¼é€Ÿåº¦ç™¾åˆ†æ¯”
    """
    if len(prices) < 5:
        return 0.0
    
    # ä½¿ç”¨æœ€è¿‘5ä¸ªä»·æ ¼ç‚¹è®¡ç®—é€Ÿåº¦
    recent = prices[-5:]
    if recent[0] > 0:
        velocity = ((recent[-1] - recent[0]) / recent[0]) * 100
        return round(velocity, 4)
    return 0.0


def calculate_volume_surge(current_volume: float, avg_volume: float) -> Dict[str, Any]:
    """
    è®¡ç®—æˆäº¤é‡æ¿€å¢
    
    Args:
        current_volume: å½“å‰æˆäº¤é‡
        avg_volume: å¹³å‡æˆäº¤é‡ï¼ˆè¿‡å»20ä¸ªå‘¨æœŸï¼‰
    
    Returns:
        Dict: {
            "surge_ratio": 1.5,  # å½“å‰/å¹³å‡
            "is_surge": True,     # æ˜¯å¦æ¿€å¢ï¼ˆ>1.5å€ï¼‰
            "magnitude": "high"   # normal/high/extreme
        }
    """
    if avg_volume == 0:
        surge_ratio = 1.0
    else:
        surge_ratio = current_volume / avg_volume
    
    is_surge = surge_ratio >= 1.5
    
    if surge_ratio >= 3.0:
        magnitude = "extreme"
    elif surge_ratio >= 1.5:
        magnitude = "high"
    else:
        magnitude = "normal"
    
    return {
        "surge_ratio": round(surge_ratio, 2),
        "is_surge": is_surge,
        "magnitude": magnitude
    }


def calculate_volatility(prices: List[float]) -> Dict[str, Any]:
    """
    è®¡ç®—æ³¢åŠ¨ç‡
    
    ä½¿ç”¨æ”¶ç›Šç‡çš„æ ‡å‡†å·®æ¥è¡¡é‡æ³¢åŠ¨
    
    Args:
        prices: ä»·æ ¼åˆ—è¡¨
    
    Returns:
        Dict: {
            "volatility": 0.8,    # æ³¢åŠ¨ç‡ç™¾åˆ†æ¯”
            "is_burst": True,     # æ˜¯å¦çˆ†å‘ï¼ˆ>1.0%ï¼‰
            "magnitude": "high"   # normal/high/extreme
        }
    """
    if len(prices) < 2:
        return {
            "volatility": 0.0,
            "is_burst": False,
            "magnitude": "normal"
        }
    
    # è®¡ç®—æ”¶ç›Šç‡
    returns = []
    for i in range(1, len(prices)):
        if prices[i-1] > 0:
            ret = (prices[i] - prices[i-1]) / prices[i-1]
            returns.append(ret)
    
    if len(returns) < 2:
        return {
            "volatility": 0.0,
            "is_burst": False,
            "magnitude": "normal"
        }
    
    # ä½¿ç”¨æœ€è¿‘20ä¸ªæ”¶ç›Šç‡è®¡ç®—æ³¢åŠ¨ç‡
    recent_returns = returns[-20:] if len(returns) >= 20 else returns
    volatility = stdev(recent_returns) * 100 if len(recent_returns) >= 2 else 0.0
    
    is_burst = volatility > 1.0
    
    if volatility > 2.0:
        magnitude = "extreme"
    elif volatility > 1.0:
        magnitude = "high"
    else:
        magnitude = "normal"
    
    return {
        "volatility": round(volatility, 4),
        "is_burst": is_burst,
        "magnitude": magnitude
    }


def calculate_stress_index(
    volatility: float,
    volume_surge_ratio: float,
    velocity: float
) -> Dict[str, Any]:
    """
    è®¡ç®—å¸‚åœºå‹åŠ›æŒ‡æ•°
    
    ç»¼åˆæ³¢åŠ¨ç‡ã€æˆäº¤é‡æ¿€å¢å’Œä»·æ ¼é€Ÿåº¦
    
    Args:
        volatility: æ³¢åŠ¨ç‡
        volume_surge_ratio: æˆäº¤é‡æ¿€å¢æ¯”ç‡
        velocity: ä»·æ ¼é€Ÿåº¦
    
    Returns:
        Dict: {
            "stress_score": 0.5,      # 0-1 ä¹‹é—´çš„å‹åŠ›åˆ†æ•°
            "regime": "moderate_stress" # calm/low_stress/moderate_stress/high_stress/extreme_stress
        }
    """
    # å½’ä¸€åŒ–å„é¡¹æŒ‡æ ‡åˆ° 0-1 èŒƒå›´
    vol_score = min(volatility / 10.0, 1.0)  # 10% æ³¢åŠ¨ = æ»¡åˆ†
    volume_score = min(volume_surge_ratio / 5.0, 1.0)  # 5å€æˆäº¤é‡ = æ»¡åˆ†
    velocity_score = min(abs(velocity) / 10.0, 1.0)  # 10% ä»·æ ¼å˜åŒ– = æ»¡åˆ†
    
    # åŠ æƒå¹³å‡
    stress_score = (
        vol_score * 0.3 +      # æ³¢åŠ¨ç‡æƒé‡ 30%
        volume_score * 0.2 +   # æˆäº¤é‡æƒé‡ 20%
        velocity_score * 0.2 + # é€Ÿåº¦æƒé‡ 20%
        0.3                     # åŸºç¡€å‹åŠ› 30%
    )
    
    # ç¡®å®šå¸‚åœºçŠ¶æ€
    if stress_score >= 0.8:
        regime = "extreme_stress"
    elif stress_score >= 0.6:
        regime = "high_stress"
    elif stress_score >= 0.4:
        regime = "moderate_stress"
    elif stress_score >= 0.2:
        regime = "low_stress"
    else:
        regime = "calm"
    
    return {
        "stress_score": round(stress_score, 3),
        "regime": regime
    }


def compute_pulse_from_bars(bars: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
    """
    ä»åŸå§‹ bar æ•°æ®è®¡ç®—å®Œæ•´çš„ pulse event
    
    Args:
        bars: åŸå§‹ bar æ•°æ®åˆ—è¡¨ï¼ˆè‡³å°‘5ä¸ªï¼‰
    
    Returns:
        Dict: å®Œæ•´çš„ pulse eventï¼ŒåŒ…å«æ‰€æœ‰æŒ‡æ ‡
    """
    if len(bars) < 5:
        logger.warning(f"Insufficient bars: {len(bars)} < 5")
        return None
    
    # æå–ä»·æ ¼å’Œæˆäº¤é‡
    prices = [bar['bar_data']['close'] for bar in bars]
    volumes = [bar['bar_data']['volume'] for bar in bars]
    
    # è·å–æœ€æ–° bar çš„ä¿¡æ¯
    latest_bar = bars[-1]
    current_price = prices[-1]
    current_volume = volumes[-1]
    timestamp = latest_bar.get('timestamp')
    
    # è®¡ç®—å„é¡¹æŒ‡æ ‡
    velocity = calculate_price_velocity(prices)
    avg_volume = mean(volumes[-20:]) if len(volumes) >= 20 else current_volume
    volume_surge = calculate_volume_surge(current_volume, avg_volume)
    volatility_burst = calculate_volatility(prices)
    
    # è®¡ç®—å‹åŠ›æŒ‡æ•°
    stress = calculate_stress_index(
        volatility=volatility_burst['volatility'],
        volume_surge_ratio=volume_surge['surge_ratio'],
        velocity=velocity
    )
    
    # æ„å»ºå®Œæ•´çš„ pulse event
    pulse_event = {
        "timestamp": timestamp,
        "ticker": latest_bar.get('ticker', 'MARKET'),
        "price": current_price,
        "volume": current_volume,
        "velocity": velocity,
        "volume_surge": volume_surge,
        "volatility_burst": volatility_burst,
        "stress": stress['stress_score'],
        "regime": stress['regime'],
        "breadth": {  # ç®€åŒ–ç‰ˆï¼Œå®é™…å¯ä»¥ä»å¤šä¸ª ticker è®¡ç®—
            "breadth": "neutral"
        }
    }
    
    return pulse_event




# ============================================================================
# ç¬¬äº”éƒ¨åˆ†ï¼šä¸»å¤„ç†æµç¨‹
# ============================================================================

def process_daily_data(date: str) -> Dict[str, Any]:
    """
    å¤„ç†æŒ‡å®šæ—¥æœŸçš„æ•°æ® (v3 - Minimal)
    
    å¤„ç†æµç¨‹ï¼š
    1. è¯»å–åŸå§‹æ•°æ®
    2. è®¡ç®— pulse eventsï¼ˆæ¯5åˆ†é’Ÿä¸€ä¸ªï¼‰
    3. å­˜å‚¨ç»“æœ
    
    Args:
        date: æ—¥æœŸå­—ç¬¦ä¸² "YYYY-MM-DD"
    
    Returns:
        Dict: å¤„ç†ç»“æœç»Ÿè®¡
    """
    logger.info(f"ğŸš€ Starting processing for {date}")
    
    # æ­¥éª¤ 1: è¯»å–åŸå§‹æ•°æ®
    raw_bars_by_ticker = read_raw_data_from_s3(date)
    
    if not raw_bars_by_ticker:
        logger.warning(f"âš ï¸  No raw data found for {date}")
        return {
            "success": False,
            "message": f"No raw data found for {date}",
            "pulse_events_count": 0
        }
    
    # æ­¥éª¤ 2: è®¡ç®— pulse events
    # ä½¿ç”¨ä¸»è¦ ticker (SPY) ä½œä¸ºå¸‚åœºä»£è¡¨
    primary_ticker = "SPY"
    if primary_ticker not in raw_bars_by_ticker:
        # å¦‚æœæ²¡æœ‰ SPYï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„ ticker
        primary_ticker = list(raw_bars_by_ticker.keys())[0]
        logger.info(f"Using {primary_ticker} as primary ticker")
    
    bars = raw_bars_by_ticker[primary_ticker]
    pulse_events = []
    
    # æ¯5åˆ†é’Ÿè®¡ç®—ä¸€ä¸ª pulse event
    window_size = 5  # 5ä¸ª1åˆ†é’Ÿbar = 5åˆ†é’Ÿçª—å£
    for i in range(0, len(bars), window_size):
        window_bars = bars[i:i+window_size]
        
        if len(window_bars) >= 5:
            pulse = compute_pulse_from_bars(window_bars)
            if pulse:
                pulse_events.append(pulse)
    
    logger.info(f"âœ… Computed {len(pulse_events)} pulse events")
    
    # æ­¥éª¤ 3: å­˜å‚¨ç»“æœåˆ° S3 (v3 - only pulse events)
    processed_prefix = f"processed-data/{date}/"
    
    # å­˜å‚¨ pulse events
    pulse_events_data = {
        "date": date,
        "processed_at": datetime.now(timezone.utc).isoformat().replace('+00:00', 'Z'),
        "events": pulse_events
    }
    
    s3_client.put_object(
        Bucket=BUCKET_NAME,
        Key=f"{processed_prefix}pulse-events.json",
        Body=json.dumps(pulse_events_data, default=str, ensure_ascii=False, indent=2),
        ContentType='application/json'
    )
    logger.info(f"âœ… Stored pulse events to S3")
    
    return {
        "success": True,
        "date": date,
        "pulse_events_count": len(pulse_events)
    }


# ============================================================================
# Lambda Handler (å…¥å£ç‚¹)
# ============================================================================

def lambda_handler(event, context):
    """
    Lambda å‡½æ•°å…¥å£ç‚¹
    
    è§¦å‘æ–¹å¼ï¼š
    1. EventBridge (å®šæ—¶): event åŒ…å« date å­—æ®µ
    2. æ‰‹åŠ¨è§¦å‘: å¯ä»¥ä¼ é€’ date å‚æ•°
    
    Args:
        event: Lambda äº‹ä»¶å¯¹è±¡
        context: Lambda ä¸Šä¸‹æ–‡
    
    Returns:
        Dict: å¤„ç†ç»“æœ
    """
    try:
        # è·å–æ—¥æœŸï¼ˆä» event æˆ–ä½¿ç”¨ä»Šå¤©ï¼‰
        date = event.get('date') or datetime.now(timezone.utc).date().isoformat()
        
        logger.info(f"ğŸ“… Processing Market Pulse data for {date}")
        logger.info(f"ğŸ“¦ Bucket: {BUCKET_NAME}")
        
        if not BUCKET_NAME:
            raise ValueError("S3_BUCKET_NAME environment variable not set")
        
        # æ‰§è¡Œå¤„ç†
        result = process_daily_data(date)
        
        logger.info(f"âœ… Processing completed: {result}")
        
        return {
            'statusCode': 200,
            'body': json.dumps(result, default=str)
        }
        
    except Exception as e:
        logger.error(f"âŒ Error processing Market Pulse data: {e}", exc_info=True)
        
        return {
            'statusCode': 500,
            'body': json.dumps({
                'success': False,
                'error': str(e)
            })
        }
